{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_train_eval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerekChuang/tensorflow_practice/blob/master/dataset_train_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ukfr1O7wAcKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Be9WE02Bga7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shutil.rmtree(\"outdir\", ignore_errors = True) # start fresh each time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPbXMWWbLh_D",
        "colab_type": "code",
        "outputId": "d50fbaf2-f8a8-416f-d149-3d871e10edfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "從桌機上載data\n",
        "\n",
        "#上載 2.csv\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# 確認 2.csv 是否已上載\n",
        "!ls *.* -l\n",
        "\n",
        "\n",
        "# use Pandas to read 2.csv\n",
        "import pandas as pd\n",
        "df = pd.read_csv('2.csv')\n",
        "print(df)\n",
        "\n",
        "'''"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n從桌機上載data\\n\\n#上載 2.csv\\nfrom google.colab import files\\n\\nuploaded = files.upload()\\n\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(\\n      name=fn, length=len(uploaded[fn])))\\n\\n# 確認 2.csv 是否已上載\\n!ls *.* -l\\n\\n\\n# use Pandas to read 2.csv\\nimport pandas as pd\\ndf = pd.read_csv(\\'2.csv\\')\\nprint(df)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "8-sbORjaLh7B",
        "colab_type": "code",
        "outputId": "76403b32-688d-4388-aa32-434a361cdc4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#掛載 google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v4v8kQbgNvXR",
        "colab_type": "code",
        "outputId": "4cf002bb-3b53-417a-958a-d3849235e702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fXlNONFZNvNx",
        "colab_type": "code",
        "outputId": "f11488f7-2e94-4a25-e37b-958a93276b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks'\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " “basic_classification.ipynb”\t\t   dataset_train_eval.ipynb\n",
            " “basic-text-classification.ipynb”的副本  'numpy&pandas_input.ipynb'\n",
            " constant_input.ipynb\t\t\t   property_prices_01.csv\n",
            " Dataset_API_intro.ipynb\t\t   property_prices_02.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FhBVcaV_PnkU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#filenames_dataset = tf.data.Dataset.list_files('/content/drive/My Drive/Colab Notebooks/property_prices_01.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xeujWKfXPngT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#filenames_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eafMmDKtBhoF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_csv(row):\n",
        "    cols = tf.decode_csv(row, record_defaults=[[0],['house'],[0]])\n",
        "    features = {'sq_footage': cols[0], 'type': cols[1]}\n",
        "    price = cols[2] # \"label\"\n",
        "    return features, price\n",
        "\n",
        "dataset = tf.data.Dataset.list_files('/content/drive/My Drive/Colab Notebooks/property*') \\\n",
        "                         .flat_map(tf.data.TextLineDataset)  \\\n",
        "                         .map(decode_csv)\n",
        "        \n",
        "dataset = dataset.shuffle(1000) \\\n",
        "                 .repeat()  \\\n",
        "                 .batch(3)\n",
        "        \n",
        "featcols = [\n",
        "    tf.feature_column.numeric_column(\"sq_footage\"),\n",
        "    tf.feature_column.indicator_column(\n",
        "        tf.feature_column.categorical_column_with_vocabulary_list(\"type\", [\"house\", \"apt\"])\n",
        "    )\n",
        "]\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "De5y22YW4FS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "@staticmethod\n",
        "list_files(\n",
        "    file_pattern,\n",
        "    shuffle=None,\n",
        "    seed=None\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "Example: If we had the following files on our filesystem: - /path/to/dir/a.txt - /path/to/dir/b.py - /path/to/dir/c.py If we pass \"/path/to/dir/*.py\" as the directory, the dataset would produce: - /path/to/dir/b.py - /path/to/dir/c.py"
      ]
    },
    {
      "metadata": {
        "id": "xfDtLol34FOU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "flat_map(map_func)\n",
        "Maps map_func across this dataset and flattens the result.\n",
        "\n",
        "为了对每个文件进行处理，可以使用Dataset.flat_map()为每个文件创建嵌套的数据集:"
      ]
    },
    {
      "metadata": {
        "id": "jYVxbBU54FJY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "使用tf.data.TextLineDataset可以从单个或多个文本文件中逐行的读取数据。"
      ]
    },
    {
      "metadata": {
        "id": "2OjEwxHg4FD1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dataset.map(f)处理数据中的每一个元素element，其中函数f(element) 需要返回一个新的元素element。"
      ]
    },
    {
      "metadata": {
        "id": "uObXLzDH4E-9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.decode_csv(\n",
        "    records,\n",
        "    record_defaults,\n",
        "    field_delim=',',\n",
        "    use_quote_delim=True,\n",
        "    name=None,\n",
        "    na_value='',\n",
        "    select_cols=None\n",
        ")"
      ]
    },
    {
      "metadata": {
        "id": "mtXv3IlK4E5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "tf.feature_column.indicator_column\n",
        "tf.feature_column.indicator_column(categorical_column)\n",
        "Defined in tensorflow/python/feature_column/feature_column.py.\n",
        "\n",
        "Represents multi-hot representation of given categorical column.\n",
        "\n",
        "For DNN model, indicator_column can be used to wrap any categorical_column_* (e.g., to feed to DNN). Consider to Use embedding_column if the number of buckets/unique(values) are large.\n",
        "\n",
        "For Wide (aka linear) model, indicator_column is the internal representation for categorical column when passing categorical column directly (as any element in feature_columns) to linear_model. See linear_model for details."
      ]
    },
    {
      "metadata": {
        "id": "vgMRNg5ITLoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn():\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "def serving_input_fn():\n",
        "    json = { 'sq_footage' : tf.placeholder(tf.int32, [None]),\n",
        "             'prop_type'  : tf.placeholder(tf.string, [None])\n",
        "           }\n",
        "        \n",
        "    features = { 'sq_footage': json['sq_footage'],\n",
        "                 'type': json['prop_type']\n",
        "               }\n",
        "    return tf.estimator.export.ServingInputReceiver(features, json)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uinADx7nTLiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "abc922d6-ea5d-4516-bc55-e18cc2c5b044"
      },
      "cell_type": "code",
      "source": [
        "# try to read the Dataset by hand\n",
        "features, labels = train_input_fn()\n",
        "with tf.Session() as sess:\n",
        "    for i in range(40):\n",
        "        feat, lab = sess.run([features, labels])\n",
        "        print(\"feat:\" + str(feat) + \" label:\" + str(lab))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feat:{'sq_footage': array([1101, 2201, 2101], dtype=int32), 'type': array([b' apt', b' apt', b' apt'], dtype=object)} label:[ 726 1351 1326]\n",
            "feat:{'sq_footage': array([1001, 1000, 2001], dtype=int32), 'type': array([b' house', b'house', b' apt'], dtype=object)} label:[ 501  500 1301]\n",
            "feat:{'sq_footage': array([1100, 2200, 2000], dtype=int32), 'type': array([b'house', b'apt', b'house'], dtype=object)} label:[ 525 1350 1000]\n",
            "feat:{'sq_footage': array([3101, 1101, 3201], dtype=int32), 'type': array([b' house', b' house', b' apt'], dtype=object)} label:[1526  526 1951]\n",
            "feat:{'sq_footage': array([1200, 1001, 3000], dtype=int32), 'type': array([b'house', b' apt', b'apt'], dtype=object)} label:[ 550  701 1900]\n",
            "feat:{'sq_footage': array([2100, 2000, 2101], dtype=int32), 'type': array([b'house', b'apt', b' house'], dtype=object)} label:[1025 1300 1026]\n",
            "feat:{'sq_footage': array([1200, 3201, 3001], dtype=int32), 'type': array([b'apt', b' house', b' house'], dtype=object)} label:[ 750 1551 1501]\n",
            "feat:{'sq_footage': array([3001, 3101, 2200], dtype=int32), 'type': array([b' apt', b' apt', b'house'], dtype=object)} label:[1901 1926 1050]\n",
            "feat:{'sq_footage': array([2201, 1100, 2001], dtype=int32), 'type': array([b' house', b'apt', b' house'], dtype=object)} label:[1051  725 1001]\n",
            "feat:{'sq_footage': array([1201, 3100, 3100], dtype=int32), 'type': array([b' house', b'house', b'apt'], dtype=object)} label:[ 551 1525 1925]\n",
            "feat:{'sq_footage': array([3200, 1201, 2100], dtype=int32), 'type': array([b'house', b' apt', b'apt'], dtype=object)} label:[1550  751 1325]\n",
            "feat:{'sq_footage': array([1000, 3200, 3000], dtype=int32), 'type': array([b'apt', b'apt', b'house'], dtype=object)} label:[ 700 1950 1500]\n",
            "feat:{'sq_footage': array([1000, 2201, 3001], dtype=int32), 'type': array([b'house', b' house', b' apt'], dtype=object)} label:[ 500 1051 1901]\n",
            "feat:{'sq_footage': array([3001, 2101, 1001], dtype=int32), 'type': array([b' house', b' apt', b' house'], dtype=object)} label:[1501 1326  501]\n",
            "feat:{'sq_footage': array([2100, 2201, 2100], dtype=int32), 'type': array([b'apt', b' apt', b'house'], dtype=object)} label:[1325 1351 1025]\n",
            "feat:{'sq_footage': array([3201, 3201, 1100], dtype=int32), 'type': array([b' apt', b' house', b'apt'], dtype=object)} label:[1951 1551  725]\n",
            "feat:{'sq_footage': array([3101, 2000, 1101], dtype=int32), 'type': array([b' house', b'house', b' house'], dtype=object)} label:[1526 1000  526]\n",
            "feat:{'sq_footage': array([1201, 2001, 1200], dtype=int32), 'type': array([b' apt', b' house', b'apt'], dtype=object)} label:[ 751 1001  750]\n",
            "feat:{'sq_footage': array([3101, 1001, 1201], dtype=int32), 'type': array([b' apt', b' apt', b' house'], dtype=object)} label:[1926  701  551]\n",
            "feat:{'sq_footage': array([3000, 3200, 2001], dtype=int32), 'type': array([b'house', b'apt', b' apt'], dtype=object)} label:[1500 1950 1301]\n",
            "feat:{'sq_footage': array([2200, 3100, 3000], dtype=int32), 'type': array([b'house', b'apt', b'apt'], dtype=object)} label:[1050 1925 1900]\n",
            "feat:{'sq_footage': array([1101, 2101, 1200], dtype=int32), 'type': array([b' apt', b' house', b'house'], dtype=object)} label:[ 726 1026  550]\n",
            "feat:{'sq_footage': array([2200, 1100, 3100], dtype=int32), 'type': array([b'apt', b'house', b'house'], dtype=object)} label:[1350  525 1525]\n",
            "feat:{'sq_footage': array([2000, 1000, 3200], dtype=int32), 'type': array([b'apt', b'apt', b'house'], dtype=object)} label:[1300  700 1550]\n",
            "feat:{'sq_footage': array([3000, 3001, 3200], dtype=int32), 'type': array([b'apt', b' apt', b'apt'], dtype=object)} label:[1900 1901 1950]\n",
            "feat:{'sq_footage': array([2200, 3100, 3201], dtype=int32), 'type': array([b'apt', b'apt', b' house'], dtype=object)} label:[1350 1925 1551]\n",
            "feat:{'sq_footage': array([1001, 2100, 2101], dtype=int32), 'type': array([b' house', b'house', b' house'], dtype=object)} label:[ 501 1025 1026]\n",
            "feat:{'sq_footage': array([2001, 2000, 3101], dtype=int32), 'type': array([b' house', b'house', b' house'], dtype=object)} label:[1001 1000 1526]\n",
            "feat:{'sq_footage': array([1201, 3101, 1000], dtype=int32), 'type': array([b' house', b' apt', b'apt'], dtype=object)} label:[ 551 1926  700]\n",
            "feat:{'sq_footage': array([3100, 1100, 1201], dtype=int32), 'type': array([b'house', b'house', b' apt'], dtype=object)} label:[1525  525  751]\n",
            "feat:{'sq_footage': array([3200, 2000, 2100], dtype=int32), 'type': array([b'house', b'apt', b'apt'], dtype=object)} label:[1550 1300 1325]\n",
            "feat:{'sq_footage': array([3000, 1101, 2101], dtype=int32), 'type': array([b'house', b' house', b' apt'], dtype=object)} label:[1500  526 1326]\n",
            "feat:{'sq_footage': array([3001, 1101, 2201], dtype=int32), 'type': array([b' house', b' apt', b' apt'], dtype=object)} label:[1501  726 1351]\n",
            "feat:{'sq_footage': array([1000, 1200, 1100], dtype=int32), 'type': array([b'house', b'house', b'apt'], dtype=object)} label:[500 550 725]\n",
            "feat:{'sq_footage': array([1001, 1200, 2201], dtype=int32), 'type': array([b' apt', b'apt', b' house'], dtype=object)} label:[ 701  750 1051]\n",
            "feat:{'sq_footage': array([3201, 2200, 2001], dtype=int32), 'type': array([b' apt', b'house', b' apt'], dtype=object)} label:[1951 1050 1301]\n",
            "feat:{'sq_footage': array([2001, 2001, 1001], dtype=int32), 'type': array([b' apt', b' house', b' apt'], dtype=object)} label:[1301 1001  701]\n",
            "feat:{'sq_footage': array([2200, 2000, 3200], dtype=int32), 'type': array([b'apt', b'house', b'house'], dtype=object)} label:[1350 1000 1550]\n",
            "feat:{'sq_footage': array([1001, 1000, 3000], dtype=int32), 'type': array([b' house', b'house', b'house'], dtype=object)} label:[ 501  500 1500]\n",
            "feat:{'sq_footage': array([3101, 3001, 2100], dtype=int32), 'type': array([b' house', b' house', b'house'], dtype=object)} label:[1526 1501 1025]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LbJ9czl1DItY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "你需要做四件事。\n",
        " \n",
        "選擇您的估算器，提供運行配置，\n",
        " \n",
        "並通過TrainSpec和EvalSpec提供培訓和測試數據。\n"
      ]
    },
    {
      "metadata": {
        "id": "tjNYwqTYTLcr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run _ config tells the estimator where and how often \n",
        "# to write Checkpoints and Tensorboard logs \n",
        "\n",
        "\n",
        "\n",
        "run_config = tf.estimator.RunConfig(model_dir=\"outdir\",\n",
        "                                    save_summary_steps=10,\n",
        "                                    save_checkpoints_steps=1000)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lC_QMgMYTLVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "export_last = tf.estimator.LatestExporter(\"houseprice\",\n",
        "                                          serving_input_fn)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uLH2jEEbTLRY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The TrainSpec tells the estimator how to get \n",
        "# training data \n",
        "\n",
        "\n",
        "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=5000)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BawsOZMwTLM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The EvalSpec controls the evaluation and the \n",
        "# checkpointing of the model since they happen at the same time \n",
        "\n",
        "\n",
        "\n",
        "eval_spec = tf.estimator.EvalSpec(input_fn=train_input_fn, ## use real evaldata !\n",
        "                                  steps=10, # evals on 100 batches\n",
        "                                  throttle_secs=3, # eval no more than every 3 sec\n",
        "                                  exporters=export_last)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jhT0uohkDAmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# train_and_evaluate"
      ]
    },
    {
      "metadata": {
        "id": "hpDvMlFeTLGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3985
        },
        "outputId": "d06933e4-c870-4a0b-ccc4-41f019b89d5b"
      },
      "cell_type": "code",
      "source": [
        "#model = tf.estimator.LinearRegressor(featcols, config=run_config)\n",
        "model = tf.estimator.DNNRegressor([3, 2, 2], featcols, config=run_config)\n",
        "\n",
        "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'outdir', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f951e6a7470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into outdir/model.ckpt.\n",
            "INFO:tensorflow:loss = 5198750.0, step = 1\n",
            "INFO:tensorflow:global_step/sec: 346.342\n",
            "INFO:tensorflow:loss = 6422720.5, step = 101 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.908\n",
            "INFO:tensorflow:loss = 4979224.5, step = 201 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.716\n",
            "INFO:tensorflow:loss = 5641325.0, step = 301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.883\n",
            "INFO:tensorflow:loss = 1650379.2, step = 401 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 723.807\n",
            "INFO:tensorflow:loss = 1250019.2, step = 501 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.367\n",
            "INFO:tensorflow:loss = 2806219.0, step = 601 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.052\n",
            "INFO:tensorflow:loss = 9307294.0, step = 701 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 882.04\n",
            "INFO:tensorflow:loss = 9633952.0, step = 801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.393\n",
            "INFO:tensorflow:loss = 9634750.0, step = 901 (0.117 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into outdir/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-08:04:59\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-08:04:59\n",
            "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1538753.4, global_step = 1000, label/mean = 1152.2, loss = 4616260.0, prediction/mean = 2.9969\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: outdir/model.ckpt-1000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
            "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'sq_footage': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
            "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'sq_footage': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-1000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: outdir/export/houseprice/temp-b'1540886699'/saved_model.pb\n",
            "INFO:tensorflow:global_step/sec: 77.5001\n",
            "INFO:tensorflow:loss = 4191038.2, step = 1001 (1.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.856\n",
            "INFO:tensorflow:loss = 3683801.0, step = 1101 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.105\n",
            "INFO:tensorflow:loss = 5782792.0, step = 1201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 774.204\n",
            "INFO:tensorflow:loss = 5096589.5, step = 1301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.113\n",
            "INFO:tensorflow:loss = 9727633.0, step = 1401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.455\n",
            "INFO:tensorflow:loss = 7635236.0, step = 1501 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 833.424\n",
            "INFO:tensorflow:loss = 3960207.2, step = 1601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.536\n",
            "INFO:tensorflow:loss = 5315661.0, step = 1701 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 837.342\n",
            "INFO:tensorflow:loss = 5734230.0, step = 1801 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 856.921\n",
            "INFO:tensorflow:loss = 6631211.0, step = 1901 (0.117 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into outdir/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (3 secs).\n",
            "INFO:tensorflow:global_step/sec: 568.184\n",
            "INFO:tensorflow:loss = 4438555.5, step = 2001 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.094\n",
            "INFO:tensorflow:loss = 5803163.0, step = 2101 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 852.802\n",
            "INFO:tensorflow:loss = 6382873.5, step = 2201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.562\n",
            "INFO:tensorflow:loss = 5832127.0, step = 2301 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.165\n",
            "INFO:tensorflow:loss = 5820282.5, step = 2401 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.385\n",
            "INFO:tensorflow:loss = 6323988.0, step = 2501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.44\n",
            "INFO:tensorflow:loss = 7143855.0, step = 2601 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.218\n",
            "INFO:tensorflow:loss = 4574452.5, step = 2701 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.626\n",
            "INFO:tensorflow:loss = 4600532.0, step = 2801 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.813\n",
            "INFO:tensorflow:loss = 2813642.8, step = 2901 (0.122 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into outdir/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-08:05:02\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-3000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-08:05:03\n",
            "INFO:tensorflow:Saving dict for global step 3000: average_loss = 1690511.2, global_step = 3000, label/mean = 1211.3, loss = 5071533.5, prediction/mean = 5.2508855\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: outdir/model.ckpt-3000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
            "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'sq_footage': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
            "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'sq_footage': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-3000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: outdir/export/houseprice/temp-b'1540886703'/saved_model.pb\n",
            "INFO:tensorflow:global_step/sec: 76.06\n",
            "INFO:tensorflow:loss = 7063093.5, step = 3001 (1.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 861.574\n",
            "INFO:tensorflow:loss = 4953567.0, step = 3101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.401\n",
            "INFO:tensorflow:loss = 4510970.5, step = 3201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.664\n",
            "INFO:tensorflow:loss = 3755665.8, step = 3301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.727\n",
            "INFO:tensorflow:loss = 6250622.0, step = 3401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.28\n",
            "INFO:tensorflow:loss = 4381842.0, step = 3501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.939\n",
            "INFO:tensorflow:loss = 4439725.5, step = 3601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 903.522\n",
            "INFO:tensorflow:loss = 3667310.8, step = 3701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.554\n",
            "INFO:tensorflow:loss = 5455730.0, step = 3801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.773\n",
            "INFO:tensorflow:loss = 5098022.5, step = 3901 (0.117 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into outdir/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (3 secs).\n",
            "INFO:tensorflow:global_step/sec: 562.986\n",
            "INFO:tensorflow:loss = 5039606.0, step = 4001 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.229\n",
            "INFO:tensorflow:loss = 4256807.5, step = 4101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.65\n",
            "INFO:tensorflow:loss = 4304966.0, step = 4201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 857.533\n",
            "INFO:tensorflow:loss = 5175137.0, step = 4301 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.059\n",
            "INFO:tensorflow:loss = 4176333.5, step = 4401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 839.889\n",
            "INFO:tensorflow:loss = 5222334.5, step = 4501 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.282\n",
            "INFO:tensorflow:loss = 3363169.0, step = 4601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.994\n",
            "INFO:tensorflow:loss = 5674522.5, step = 4701 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 834.297\n",
            "INFO:tensorflow:loss = 7252170.0, step = 4801 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.977\n",
            "INFO:tensorflow:loss = 3306850.0, step = 4901 (0.115 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into outdir/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-30-08:05:06\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-30-08:05:06\n",
            "INFO:tensorflow:Saving dict for global step 5000: average_loss = 1526493.6, global_step = 5000, label/mean = 1147.2, loss = 4579481.0, prediction/mean = 6.8027096\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: outdir/model.ckpt-5000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
            "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'sq_footage': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
            "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'sq_footage': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'prop_type': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>}\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:Restoring parameters from outdir/model.ckpt-5000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: outdir/export/houseprice/temp-b'1540886706'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 6086393.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'average_loss': 1526493.6,\n",
              "  'global_step': 5000,\n",
              "  'label/mean': 1147.2,\n",
              "  'loss': 4579481.0,\n",
              "  'prediction/mean': 6.8027096},\n",
              " [b'outdir/export/houseprice/1540886706'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "Ct6hq6VhOYjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5287df74-0116-47f3-b700-739ccd76d4f6"
      },
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  outdir  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-pK8PyXOYeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GgvwuwwOYaM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SW3hg0F3OYWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPgM-lLkOYR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55evRzopBkPS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PYTpMgm-BoK5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}